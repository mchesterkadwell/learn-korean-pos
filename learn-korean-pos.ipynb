{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Korean Learner Parts of Speech Tagger\n",
    "When beginning to learn the Korean language, it is sometimes hard to tell which parts of words are grammatical particles and which parts are substantive root words you can look up in the dictionary.\n",
    "\n",
    "This project aims to make it easier for Korean language learners to decode written Korean sentences, by marking up particles and other grammatical parts. It is not a translation tool as such, but rather a project to help with sentence decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.utils import pprint\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use 'Open Korean Text'\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# text = '김장 행사에 참여한 아동·청소년 봉사자들은 자신들이 먹을 김치를 직접 만들면서 한편으로 다른 소외계층을 위한 나눔 활동을 한다는 사실에 뿌듯함을 느꼈다.'\n",
    "text = '나는 케이크를 먹고있다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('나', 'Noun'), ('는', 'Josa'), ('케이크', 'Noun'), ('를', 'Josa'), ('먹고있다', 'Verb')]\n"
     ]
    }
   ],
   "source": [
    "# We don't want to normalise as we want to mark up the original string with information\n",
    "pos = okt.pos(text, norm=False, stem=False)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Korean</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>는</td>\n",
       "      <td>Particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>케이크</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>를</td>\n",
       "      <td>Particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>먹고있다</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Korean       POS\n",
       "0      나      Noun\n",
       "1      는  Particle\n",
       "2    케이크      Noun\n",
       "3      를  Particle\n",
       "4   먹고있다      Verb"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = DataFrame(pos, columns=['Korean', 'POS'])\n",
    "words_df.drop(words_df[words_df.POS == \"Punctuation\"].index, inplace=True)\n",
    "words_df.POS.replace({'Josa': 'Particle'}, inplace=True)\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Korean</th>\n",
       "      <th>POS</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나</td>\n",
       "      <td>Noun</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>는</td>\n",
       "      <td>Particle</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>케이크</td>\n",
       "      <td>Noun</td>\n",
       "      <td>Cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>를</td>\n",
       "      <td>Particle</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>먹고있다</td>\n",
       "      <td>Verb</td>\n",
       "      <td>I'm eating.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Korean       POS      English\n",
       "0      나      Noun            I\n",
       "1      는  Particle             \n",
       "2    케이크      Noun         Cake\n",
       "3      를  Particle             \n",
       "4   먹고있다      Verb  I'm eating."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This suppresses the following warning, but take note it will also suppress all other warnings as well.\n",
    "# 'UserWarning: 샘플키로 요청합니다' means you need to get a proper developer token from developers.naver.com but it will still work with sample key.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from naipy import sync\n",
    "from naipy.model import N2mtNaipy\n",
    "\n",
    "naipy = sync.Translation()\n",
    "\n",
    "# Get translations for all tokens\n",
    "# words_df['English'] = words_df['Korean'].apply(naipy.translation, args=('en',)).apply(getattr, args=('translatedText',))\n",
    "\n",
    "# Only get translations for non-particle tokens since Naver translation for particles is useless\n",
    "words_df['English'] = words_df.apply(lambda x: N2mtNaipy('') if x.POS == 'Particle' else naipy.translation(x.Korean, 'en'), axis=1).apply(getattr, args=('translatedText',)).apply(lambda y: '' if y == None else y)\n",
    "\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the basic information we need we want to use this mark up a visualisation of the original sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Acknowledgements\n",
    "This project builds on a blog post by Niamh Kinglsey that I came across while researching my idea. They have done a good job of starting on the journey I wanted to go on to.\n",
    "https://towardsdatascience.com/how-i-used-python-code-to-improve-my-korean-2f3ae09a9773\n",
    "\n",
    "Eunjeong L. Park, Sungzoon Cho. “[KoNLPy: Korean natural language processing in Python](http://dmlab.snu.ac.kr/~lucypark/docs/2014-10-10-hclt.pdf)”, Proceedings of the 26th Annual Conference on Human & Cognitive Language Technology, Chuncheon, Korea, Oct 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}